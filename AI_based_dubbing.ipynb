{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3ZP0mYseBpHh",
        "edtSYdRoBflw",
        "Leok8_uBEmdQ",
        "kijafOhrEGoB",
        "1LoYBJWaEJVy",
        "VQXoZmv7EeHl",
        "S95jSasHHrYP",
        "JTXbqFxtH3Hf",
        "UrB8RFKtIVBb",
        "cfvY9Jr8JFLY",
        "D6UsNnc3-YaE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install requirements"
      ],
      "metadata": {
        "id": "3ZP0mYseBpHh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXRXkhp2-Jh5"
      },
      "outputs": [],
      "source": [
        "!pip uninstall numpy\n",
        "!pip install --upgrade numpy==1.23\n",
        "!pip install pydub\n",
        "!pip install pyannote.audio\n",
        "!pip install tts\n",
        "!pip install azure-cognitiveservices-speech azure-ai-textanalytics\n",
        "!pip install noisereduce soundfile\n",
        "!pip install speech_recognition\n",
        "!pip install googletrans\n",
        "!pip install gtts\n",
        "!pip install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import necessary libraries"
      ],
      "metadata": {
        "id": "edtSYdRoBflw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from pyannote.audio import Pipeline\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import os\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "from azure.ai.textanalytics import TextAnalyticsClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "import moviepy.editor as mp\n",
        "import time\n",
        "#import noisereduce as nr\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "#import speech_recognition as sr\n",
        "from transformers import pipeline\n",
        "from googletrans import Translator\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "import ffmpeg"
      ],
      "metadata": {
        "id": "OvomcRc5-VY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Global variables"
      ],
      "metadata": {
        "id": "Leok8_uBEmdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Azure credentials\n",
        "speech_key = \"****\"\n",
        "speech_region = \"eastus\"\n",
        "translator_key = \"****\"\n",
        "translator_endpoint = \"https://api.cognitive.microsofttranslator.com/\"\n",
        "\n",
        "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=False)"
      ],
      "metadata": {
        "id": "alVbJblLEpo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "u5WUdVLwDhqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reduce Noise"
      ],
      "metadata": {
        "id": "kijafOhrEGoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_noise(input_audio_path, output_audio_path, noise_reduction_level=0.1):\n",
        "    \"\"\"\n",
        "    Remove background noise from audio.\n",
        "    Args:\n",
        "        input_audio_path (str): Path to the input audio file.\n",
        "        output_audio_path (str): Path to save the noise-reduced audio file.\n",
        "        noise_reduction_level (float): The amount of noise reduction (0 to 1).\n",
        "    \"\"\"\n",
        "    # Load the audio file\n",
        "    audio_data, sample_rate = librosa.load(input_audio_path, sr=None)\n",
        "\n",
        "    # Perform noise reduction using spectral gating\n",
        "    reduced_noise = librosa.effects.reduce_noise(y=audio_data, sr=sample_rate, prop_decrease=noise_reduction_level)\n",
        "\n",
        "    # Save the noise-reduced audio file\n",
        "    write(output_audio_path, sample_rate, (reduced_noise * 32767).astype(np.int16))\n",
        "    print(f\"Noise-reduced audio saved at {output_audio_path}\")"
      ],
      "metadata": {
        "id": "IFayDVlGDfEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Video to audio"
      ],
      "metadata": {
        "id": "1LoYBJWaEJVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_audio_from_video(video_file, output_audio_file):\n",
        "    print(\"Extracting audio from video...\")\n",
        "    video = mp.VideoFileClip(video_file)\n",
        "    video.audio.write_audiofile(output_audio_file)\n",
        "    print(f\"Audio saved to {output_audio_file}\")"
      ],
      "metadata": {
        "id": "DRjS4iihER9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Speech to text"
      ],
      "metadata": {
        "id": "VQXoZmv7EeHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(audio_file_path, source_language):\n",
        "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
        "    speech_config.speech_recognition_language = source_language  # Set the source language (e.g., \"fr-FR\" for French)\n",
        "    audio_config = speechsdk.AudioConfig(filename=audio_file_path)\n",
        "\n",
        "    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
        "\n",
        "    print(f\"Transcribing audio file in {source_language}...\")\n",
        "    result = recognizer.recognize_once()\n",
        "\n",
        "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
        "        print(f\"Transcription: {result.text}\")\n",
        "        return result.text\n",
        "    else:\n",
        "        print(f\"Error transcribing audio: {result.reason}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "YguHxdpdEgff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Translate"
      ],
      "metadata": {
        "id": "S95jSasHHrYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_text(transcription, target_language):\n",
        "    import requests\n",
        "    import uuid\n",
        "\n",
        "    # Prepare the translation request\n",
        "    path = '/translate?api-version=3.0'\n",
        "    params = f'&to={target_language}'\n",
        "    constructed_url = translator_endpoint + path + params\n",
        "\n",
        "    headers = {\n",
        "        'Ocp-Apim-Subscription-Key': translator_key,\n",
        "        'Ocp-Apim-Subscription-Region': speech_region,\n",
        "        'Content-type': 'application/json',\n",
        "        'X-ClientTraceId': str(uuid.uuid4())\n",
        "    }\n",
        "\n",
        "    body = [{'text': transcription}]\n",
        "\n",
        "    request = requests.post(constructed_url, headers=headers, json=body)\n",
        "    response = request.json()\n",
        "\n",
        "    translated_text = response[0][\"translations\"][0][\"text\"]\n",
        "    print(f\"Translated Text: {translated_text}\")\n",
        "    return translated_text"
      ],
      "metadata": {
        "id": "75Fdt3ihHxDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text to Speech"
      ],
      "metadata": {
        "id": "JTXbqFxtH3Hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_speech(text, output_file, original_audio, target_language):\n",
        "    tts.tts_to_file(text=text, file_path=output_file, speaker_wav=original_audio, language=target_language)"
      ],
      "metadata": {
        "id": "doOkqXv8H70u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Replace original audio with dubbed audio in Video\n"
      ],
      "metadata": {
        "id": "UrB8RFKtIVBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mute_original_audio(input_video_path, output_muted_video_path):\n",
        "    \"\"\"\n",
        "    Mute the original audio in the video.\n",
        "\n",
        "    Args:\n",
        "        input_video_path (str): Path to the input video file.\n",
        "        output_muted_video_path (str): Path to save the muted output video.\n",
        "    \"\"\"\n",
        "    subprocess.run([\n",
        "        'ffmpeg', '-i', input_video_path, '-c', 'copy', '-an', output_muted_video_path\n",
        "    ], check=True)\n",
        "    print(f\"Muted video saved at: {output_muted_video_path}\")\n",
        "\n",
        "def replace_audio(input_video_path, input_audio_path, output_video_path):\n",
        "    \"\"\"\n",
        "    Replace the original audio in a video with new audio.\n",
        "\n",
        "    Args:\n",
        "        input_video_path (str): Path to the input muted video file.\n",
        "        input_audio_path (str): Path to the new audio file.\n",
        "        output_video_path (str): Path to save the final video with replaced audio.\n",
        "    \"\"\"\n",
        "    subprocess.run([\n",
        "        'ffmpeg', '-i', input_video_path, '-i', input_audio_path, '-c:v', 'copy', '-c:a', 'aac', '-strict', 'experimental', output_video_path\n",
        "    ], check=True)\n",
        "    print(f\"Final video with replaced audio saved at: {output_video_path}\")"
      ],
      "metadata": {
        "id": "NDR3FndOIcDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Change audio Speed"
      ],
      "metadata": {
        "id": "cfvY9Jr8JFLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def change_audio_speed(audio_path, output_path, speed_factor):\n",
        "    \"\"\"\n",
        "    Speed up or slow down audio by changing the playback speed.\n",
        "\n",
        "    :param audio_path: Path to the input audio file.\n",
        "    :param output_path: Path to save the output file.\n",
        "    :param speed_factor: Factor by which to change the speed (e.g., 1.5 for 1.5x faster, 0.5 for 0.5x slower).\n",
        "    \"\"\"\n",
        "    # Load the audio file\n",
        "    audio = AudioSegment.from_file(audio_path)\n",
        "\n",
        "    # Modify playback speed (this changes both pitch and speed)\n",
        "    new_sample_rate = int(audio.frame_rate * speed_factor)\n",
        "\n",
        "    # Create new AudioSegment with updated frame rate\n",
        "    new_audio = audio._spawn(audio.raw_data, overrides={'frame_rate': new_sample_rate})\n",
        "\n",
        "    # Set the new frame rate and export the modified audio\n",
        "    new_audio = new_audio.set_frame_rate(audio.frame_rate)\n",
        "    new_audio.export(output_path, format=\"wav\")\n",
        "    print(f\"Audio saved at: {output_path}\")\n",
        "\n",
        "    return new_audio"
      ],
      "metadata": {
        "id": "C84cPAaZJKVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Segregate speaker's voice"
      ],
      "metadata": {
        "id": "D6UsNnc3-YaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segregate_speakers(audio_path, output_dir=\"output_segments\"):\n",
        "    \"\"\"\n",
        "    Segregates different speaker's voices and returns their timestamps and audio segments.\n",
        "\n",
        "    :param audio_path: Path to the input audio file.\n",
        "    :param output_dir: Directory where speaker audio segments will be saved.\n",
        "    :return: List of dictionaries containing speaker label, timestamps, and segment path.\n",
        "    \"\"\"\n",
        "    # Initialize pre-trained speaker diarization pipeline\n",
        "    pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\")\n",
        "\n",
        "    # Perform diarization on the input audio file\n",
        "    diarization = pipeline(audio_path)\n",
        "\n",
        "    # Load the original audio using pydub\n",
        "    audio = AudioSegment.from_wav(audio_path)\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Create a dictionary to store speaker segments\n",
        "    speaker_data = {}\n",
        "\n",
        "    # Iterate over diarization results and save each segment\n",
        "    for i, (segment, speaker) in enumerate(diarization.itertracks(yield_label=True)):\n",
        "        # Convert start and end times from seconds to milliseconds\n",
        "        start_time = segment.start * 1000\n",
        "        end_time = segment.end * 1000\n",
        "\n",
        "        # Extract the audio segment for this speaker\n",
        "        audio_segment = audio[start_time:end_time]\n",
        "\n",
        "        # Save the audio segment to a file\n",
        "        segment_filename = os.path.join(output_dir, f\"speaker_{speaker}_segment_{i}.wav\")\n",
        "        audio_segment.export(segment_filename, format=\"wav\")\n",
        "\n",
        "        # Store each segment in the speaker's dictionary\n",
        "        if speaker not in speaker_data:\n",
        "            speaker_data[speaker] = []\n",
        "        speaker_data[speaker].append({\n",
        "            'start_time': segment.start,\n",
        "            'end_time': segment.end,\n",
        "            'audio_path': segment_filename\n",
        "        })\n",
        "\n",
        "    return speaker_data"
      ],
      "metadata": {
        "id": "rVAv5Kgc-0tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dub (main function)"
      ],
      "metadata": {
        "id": "xgwrwUM0JxZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to run the process\n",
        "def DubVideo(input_video_file, target_language, source_language=\"en-US\"):\n",
        "\n",
        "    # Step 1: Extract the original audio from the video\n",
        "    original_audio_file = input_video_file.split(\".mp4\")[0] + \".wav\"\n",
        "    extract_audio_from_video(input_video_file, original_audio_file)\n",
        "\n",
        "    # Step 2: Transcribe the original audio in the specified source language\n",
        "    transcription = transcribe_audio(original_audio_file, source_language)\n",
        "    if not transcription:\n",
        "        print(\"Transcription failed.\")\n",
        "        return\n",
        "\n",
        "    # Step 3: Translate the transcription into the target language\n",
        "    translated_text = translate_text(transcription, target_language)\n",
        "\n",
        "    # Step 4: Convert the translated text back to speech\n",
        "    output_audio_file = original_audio_file.split(\".wav\")[0] + \"_dubbed.wav\"\n",
        "    text_to_speech(translated_text, output_audio_file, original_audio_file, target_language)\n",
        "\n",
        "    # Step 2: Reduce noise in the extracted audio\n",
        "    reduce_noise(output_audio_file, output_audio_file)\n",
        "\n",
        "    # Step 5: Replace the audio in the original video\n",
        "    output_video_file = input_video_file.split(\".mp4\")[0] + \"_dubbed.wav\"\n",
        "    replace_audio_in_video(input_video_file, output_audio_file, output_video_file)"
      ],
      "metadata": {
        "id": "Whym3pqaAcmc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
